# Project1
#Introduction
MapReduce is a programming model based on the idea of dividing a large computational problem into smaller sub-problems that can be processed separately in parallel. The framework consists of two main components: a map phase and a reduce phase. The input data is first split into a set of key-value pairs in the mapper, then passes these pairs to the reducer phase, aggregating them to produce a set of output values. In some complicated cases, it also allows running multiple rounds of MapReduce to get the desired results. It allows multiple machines to handle the tasks in a cluster, making it possible to analyze large datasets efficiently. This project aims to solve two data analysis problems using Hadoop MapReduce-based program. For the first part, we concentrated on the New York City (NYC) Parking Violations data to identify the most common time and location tickets issued, the most usual years and types of cars being ticketed, and the color of cars that get parking tickets the most frequently. The second part involved analyzing the NBA shots taken during the 2014-2015 seasons. We aimed to determine each player's "most unwanted defender" based on the fear score. Additionally, we aimed to classify each player's records into four comfortable zones and then considered which zone was the best for James Harden, Chris Paul, Stephen Curry, and LeBron James with the hit rate. To do this, we developed our own Python implementation of the MapReduce framework to analyze the data. Our implementation followed one or multiple rounds of the MapReduce approach. 

#Dataset Description
This data set must place at dir: "/mapreduce-test/mapreduce-test-python/proj1/q1", and the file name of this csv file must be "data.csv"!}

The dataset on NYC Parking Violations is collected by the NYC Department of Finance every year. It is hosted and publicly accessible on the platform known as NYC Open Data, which attempts to give open access to a variety of datasets and data resources published and managed by New York City government organizations. The NYC Parking Violation dataset contains the information on each ticket violation record in New York City. The dataset contains a total of 11535314 rows representing each ticket and 43 columns with more detailed information, such as the date, location the violation occurred, and much more, including the information of vehicles, such as the type and the color of vehicles. 

This data set must place at dir: "/mapreduce-test/mapreduce-test-python/proj1/q2", and the file name of this csv file must be "shot\_logs.csv"!}

The dataset on NBA Shot Logs records the shots taken during the 2014-2015 season, which provides a rich source of data on the shot-taking behaviour of NBA players. The dataset includes 128069 rows that represent each shot attempts taken by each player throughout the season, and 21 columns show information on who took the shots, who was the nearest defender, time on the shot clock, and much more.  

#MapReduce
In the first part, we were expected to set up the Hadoop Mapreduce-based framework along with the scheduler for resource management to analyze the violation tickets situation in New York City. We used the NYC Parking Violations 2023 dataset. We analyzed the ticket violations situation during the period of 6/10/2022 to 2/23/2023. Specifically, we were going to answer the following four questions: 
When are tickets most likely to be issued?
For this question, we developed a single round of MapReduce.  The purpose of our MapReduce script was to extract the time values from the input dataset, round them down to the nearest hour, and output the resulting hours along with a count of 1 for each hour. This output could then be used as input to a MapReduce job to produce a count of events per hour. 
From our result, the most often time tickets get issued was 9:00 AM with 999544 counts. 

What are the most common years and types of cars to be ticketed?
For this question, we developed a two-round of MapReduce. In the first Mapreduce we extracted the value of years and types from input data and then produced a year and made, along with 1 a key-value pair at mapper phase. Then passed to the reducer and printed out the aggregated counts of each car year-type pair as our first round of MapReduce outputs. The second MapReduce program chose the year and type of cars with the highest frequency and emitted it as a key-value pair along with the count for each group of key-value pairs with the exact count. Our program showed that the most common years and types of cars to be ticketed was 2021, SUBN, with counts 574105.

Where are tickets most commonly issued?
For this question, we developed two rounds of MapReduce. From first MapReduce program we got the aggregated counts for each street and location for this station, as the key-value pairs of a combination of street code and location as keys, counts as values. The second MapReduce aggregated the counts and printed the final counts for each location. Our outputs showed that the 3rd Ave, street code 0019, was the ticket most commonly issued place, with counts 31607. 

Which color of the vehicle is most likely to get a ticket?
For this question, we deveoped three rounds of Mapreduce. We used the first round of MapReduce that generated the key-value pairs of color and counts, and then got the aggregated counts for each color at the reducer phase, and followed by the second round of MapReduce to make the counts could be sorted by producing new key-value pairs. After this, we used another round of MapReduce to group the same color meaning together of the top 20 colors with most frequency. As a result, we found that WHITE vehicles, with 2781715 times, were the most likely to be ticketed. 

In the second part, our purpose was to analyze the NBA Shot Logs dataset during the 2014-2015 season. We were expected to answer the following two questions:
For each pair of the players (A, B), we define the fear sore of A when facing B is the hitrate, such that B is closet defender when A is shoting. Based on the fear sore, for each player, please find out who is his ”most unwanted defender”;
Please develop a MapReduce-based algorithm to classify each player’s records into 4 comfortable zones. Considering the hit rate, which zone is the best for James Harden, Chris Paul, Stephen Curry and Lebron James.

To identify the player's "most unwanted defender" for each player, we designed a two-round Mapreduce. Each round of MapReduce plays a different role in solving this question. We used the first MapReduce to determine the fear score for each shooter/defender pair, which was the shooting result when the shooter faced the defender. The second MapReduce we designed to find out the player's most "unwanted defender", for each player based on the fear score we calculated manually from the first phase. 

For this question, we need to classify the shooting player's comfortable zones with the criteria: {SHOT DIST, CLOSE DEF DIST, SHOT CLOCK}. We built the classifier as Zone1: Close shot and got contested in regular time:(shot with 5 feet, the defender is in 3 feet, and the shot clock is in regular time); Zone2: Shots beyond 5 feet and got contested in regular time: (shot over 5 feet, the defender is in 3 feet and the shot clock is in regular time); Zone3: wide-open shots in regular time: (shot from anywhere open, the defender is farther than 3 feet and the shot clock is in regular time); zone4 is otherwise, which means that it is in clutch time:(shoot from anywhere no matter if any defender is contesting). In our first mapper function, we divide the metrics(matrix) into four zones and output each player's shots with a key-value pair with (zone number, made?, 1). Then the stream will push to the reducer1, and the reducer will calculate the hit rate and aggregate each player's every zone along with their hit rates(output:(info, made, attempt, hit rate). In the second mapper, we did not make anything unique, and in reducer2, we found the largest hit rate of their zones for each player. Then we would output the zones with their highest hit rate for each player. This would result in our map reduce process.  
